# Процессы и потоки

## 1. Общие понятия

Процесс – это исполняемая копия приложения. Например, когда вы открываете приложение MS Word, то
запускаете процесс, исполняющий программу MS Word. Поток – отдельное исполняемое задание внутри
процесса. Процесс может содержать множество исполняемых потоков. После запуска приложения
исполняется главный поток, который далее может порождать другие потоки.

Каждый процесс обладает собственной памятью. Потоки же, которые запущены внутри процесса,
разделяют память между собой. Процесс внутри операционной системы обладает собственным
идентификатором. Потоки существуют внутри процесса и обладают идентификатором внутри работающего
приложения. Каждый из потоков имеет свой собственный стек (он не делит его с другими потоками и
другие потоки не могут в него залезть) и собственный набор регистров (поток не изменит значения
регистра другого потока во время работы). Часто потоки называют «легковесными» процессами, так как
они требуют гораздо меньше ресурсов для работы, чем новый процесс. В зависимости от реализации,
обычный настольный компьютер может эффективно использовать от единиц, до десятков тысяч потоков.

## 2. Многопоточное программирование

Модуль threading впервые был представлен в Python 1.5.2 как продолжение низкоуровневого модуля
потоков. Модуль threading значительно упрощает работу с потоками и позволяет программировать запуск
нескольких операций одновременно. Обратите внимание на то, что потоки в Python лучше всего работают
с операциями I/O, такими как загрузка ресурсов из интернета или чтение файлов и папок на вашем
компьютере.

Если вам нужно сделать что-то, для чего нужен интенсивный CPU, тогда вам, возможно, захочется
взглянуть на модуль multiprocessing, вместо threading. Причина заключается в том, что Python
содержит Global Interpreter Lock (GIL), который запускает все потоки внутри главного потока. По
этой причине, когда вам нужно запустить несколько интенсивных операций с потоками, вы заметите, что
все работает достаточно медленно. Так что мы сфокусируемся на том, в чем потоки являются лучшими:
операции I/O.

Создадим два простых потока и проанализируем их работу

```python
from threading import Thread
from time import sleep


def func1(start, end):
    while start < end:
        print("Func1: %s" % start)
        start += 1
        sleep(1)


def func2(start, end):
    while start < end:
        print("Func2: %s" % start)
        start += 1
        sleep(0.5)


thread1 = Thread(target=func1, args=(3, 10))
thread2 = Thread(target=func2, args=(5, 20))
thread1.start()
thread2.start()

print("END")
```

Мы объявили две функции - `func1` и `func2`, которые должны выполняться параллельно в двух потоках.
Каждая из этих функций просто увеличивает свой внутренний счётчик и выводит его значение на экран.
Далее на основе этих функций создаём два объекта потока класса `Thread`, в конструктор которого
передаём функцию для выполнения (`target`) и аргументы, с которыми будет вызываться эта функция
(`args`). После этого последовательно запускаем потоки методом `start`. В этот момент параллельно
главному потоку запускаются дочерние, теперь 3 потока выполняются одновременно.

Как вы могли заметить, сначала выводится END, а потом производится выполнение потоков. Так
происходит, потому что главный поток не останавливается при запуске дочерних потоков. Как только
главный поток выполнится - он будет ждать завершения дочерних потоков.

Это поведение можно изменить, объявив потоки как демоны. Таким образом главный поток не будет
следить за дочерними и завершится. Но вместе с главным потоком одновременно завершится работа и
дочерних потоков.

```python
from threading import Thread
from time import sleep


def func1(start, end):
    while start < end:
        print("Func1: %s" % start)
        start += 1
        sleep(1)


def func2(start, end):
    while start < end:
        print("Func2: %s" % start)
        start += 1
        sleep(0.5)


thread1 = Thread(target=func1, args=(3, 10), daemon=True)  # Поток-демон
thread2 = Thread(target=func2, args=(5, 20), daemon=True)  # Поток-демон
thread1.start()
thread2.start()

print("END")
```

Чтобы явно указать, что главный поток должен дождаться работы дочерних потоков, нужно вызвать
метод `join` для каждого потока.

```python
from threading import Thread
from time import sleep


def func1(start, end):
    while start < end:
        print("Func1: %s" % start)
        start += 1
        sleep(1)


def func2(start, end):
    while start < end:
        print("Func2: %s" % start)
        start += 1
        sleep(0.5)


thread1 = Thread(target=func1, args=(3, 10), daemon=True)
thread2 = Thread(target=func2, args=(5, 20), daemon=True)
thread1.start()
thread2.start()

for i in range(5):                                         # Полезная нагрузка на главный поток
    print("MAIN THREAD")
    sleep(0.5)

thread1.join()
print("Func1 end")
thread2.join()
print("Func2 end")

print("END")
```

Метод `join` приостанавливает поток, в котором он был вызван и ожидает окончания того потока,
объект которого вызывал метод `join`. В данном примере главный поток сначала ждёт окончания первого
потока, потом второго.

Функции `func1` и `func2` имеют очень похожий функционал. Мы можем объединить их в одну.

```python
from threading import Thread
from time import sleep


def func(name, start, end, timeout):
    while start < end:
        print(f"Thread {name}: {start}")
        start += 1
        sleep(timeout)


thread1 = Thread(target=func1, args=("Func1", 3, 10, 1), daemon=True)
thread2 = Thread(target=func2, args=("Func2", 5, 20, 0.5), daemon=True)
thread1.start()
thread2.start()

for i in range(5):
    print("MAIN THREAD")
    sleep(0.5)

thread1.join()
print("Func1 end")
thread2.join()
print("Func2 end")

print("END")
```

Рассмотрим создание собственного класса потока:

```python
from threading import Thread
from time import sleep


class MyThread(Thread):
    def __init__(self, name, begin, end, timeout):
        super().__init__(self)
        self.name = name
        self.begin = begin
        self.end = end
        self.timeout = timeout

    def run(self):
        while self.begin < self.end:
            print(f"Thread {self.name}: {self.begin}")
            self.begin += 1
            sleep(self.timeout)


thread1 = MyThread(name="1", begin=3, end=10, timeout=1)
thread2 = MyThread(name="2", begin=5, end=20, timeout=0.5)

thread1.start()
thread2.start()

for i in range(5):
    print("MAIN THREAD")
    sleep(0.5)

thread1.join()
thread2.join()

print("END")
```

Когда у вас в распоряжении более одного потока, тогда вам, возможно, понадобится понять, как
избежать конфликтов. Под этим я имею ввиду то, что вы можете использовать случай, где более одного
потока нуждаются в доступе к одном и тому же ресурсу в одно и то же время. Если вы не думаете о
таких проблемах и соответственном планировании, тогда вы можете столкнуться с самыми худшими
проблемами в крайне неудобное время, и, как правило, в момент выпуска кода.

Решение проблемы – это использовать замки. Замок предоставлен модулем Python threading и может
держать один поток, или не держать поток вообще. Если поток пытается acquire замок на ресурсе,
который уже закрыт, этот поток будет ожидать до тех пор, пока замок не откроется.
Рассмотрим пример предыдущих потоков с замками:

```python
from threading import Thread, Lock
from time import sleep


class MyThread(Thread):
    def __init__(self, name, end, timeout):
        super().__init__(self)
        self.name = name
        self.end = end
        self.timeout = timeout

    def run(self):
        while count < self.end:
            print(f"Thread {self.name}: {count}")

            lock.acquire()
            try:
                count += 1
            finally:
                lock.release()

            sleep(self.timeout)


count = 0
lock = Lock()

thread1 = MyThread(name="1", end=10, timeout=1)
thread2 = MyThread(name="2", end=20, timeout=0.5)

thread1.start()
thread2.start()

for i in range(5):
    print("MAIN THREAD")
    sleep(0.5)

thread1.join()
thread2.join()

print("END")
```

Есть шанс того, что вы можете забыть раскрыть замок после выполнения критического участка кода или
во время выполнения кода будет выброшено исключение и поток не раскроет замок. В таком случае можно
использовать замок в менеджере контекса `with`:

```python
with lock:
    [Критический код]
```

## 3. GIL

Python Global Interpreter Lock (GIL) — это своеобразная блокировка, позволяющая только одному потоку
управлять интерпретатором Python. Это означает, что в любой момент времени будет выполняться только
один конкретный поток.

Работа GIL может казаться несущественной для разработчиков, создающих однопоточные программы. Но во
многопоточных программах отсутствие GIL может негативно сказываться на производительности
процессоро-зависимых программ.

Поскольку GIL позволяет работать только одному потоку даже в многопоточном приложении, он заработал
репутацию «печально известной» функции.

Python подсчитывает количество ссылок для корректного управления памятью. Это означает, что
созданные в Python объекты имеют переменную подсчёта ссылок, в которой хранится количество всех
ссылок на этот объект. Как только эта переменная становится равной нулю, память, выделенная под этот
объект, освобождается.

Проблема, которую решает GIL, связана с тем, что в многопоточном приложении сразу несколько потоков
могут увеличивать или уменьшать значения этого счётчика ссылок. Это может привести к тому, что
память очистится неправильно и удалится тот объект, на который ещё существует ссылка.

## 4. Мультипроцессное программирование

Несмотря на то, что процессы и потоки имеют серьёзные различия, создание и запуск нескольких
параллельных процессов на языке Python очень сильно похоже на работу с потоками. Для взаимодействия
с потоками используется библиотека `multiprocessing`.

Создадим два процесса и запустим их

```python
from multiprocessing import Process
import os
from time import sleep


def func(start, end, timeout):
    while start < end:
        print(f"Process {os.getpid()}: {start}")
        start += 1
        sleep(timeout)


process1 = Process(target=func1, args=(3, 10, 1))
process2 = Process(target=func2, args=(5, 20, 0.5))
process1.start()
process2.start()

print("END")
```

С помощью класса `Process` создаём объекты процессов и вызывая внутренние методы `start` запускаем
каждый процесс. Вы можете заметить, что как и в ситуации с потоками, сначала выведется "END", а
потом будут выполняться процессы.

Есть вероятность того, что данный код сгенерирует исключение. Это говорит о том, что вы запустили
его на Windows.

Дело в том, что работа с процессами в разных операционных системах устроена по разному. В Unix
данный код отработает нормально благодаря своему механизму создания процесса. Процесс создаётся
с помощью функции `fork` из модуля `os`, которая полностью копирует дочерний процесс и продолжает
его выполнение. Такая возможность есть только в Unix-подобный операционных системах.

В Windows запуск нового процесса выглядит совсем иначе. Для запуска процесса Windows снова вызывает
интерпретатор и запускает в нём тот же модуль, внутри которого создаются дочерние процессы. Таким
образом появляется бесконечная рекурсия.

Но есть один нюанс: внутри каждого модуля есть переменная `__name__`. Для запускаемого модуля по
умолчанию она равна `__main__`, но если модуль был запущен в дочернем потоке, то её значение будет
`__mp_main__`. Таким образом установив простое условие можно избежать рекурсии.

```python
from multiprocessing import Process
import os
from time import sleep


def func(start, end, timeout):
    while start < end:
        print(f"Process {os.getpid()}: {start}")
        start += 1
        sleep(timeout)


if __name__ == "__main__":
    process1 = Process(target=func1, args=(3, 10, 1))
    process2 = Process(target=func2, args=(5, 20, 0.5))
    process1.start()
    process2.start()

    print("END")
```

Такой код будет работать на всех операционных системах.

Главный процесс так же дожидается, когда закончится выполнение дочерних процессов. Это поведение
можно изменить, сделав процессы демонами.

```python
from multiprocessing import Process
import os
from time import sleep


def func(start, end, timeout):
    while start < end:
        print(f"Process {os.getpid()}: {start}")
        start += 1
        sleep(timeout)


if __name__ == "__main__":
    process1 = Process(target=func1, args=(3, 10, 1), daemon=True)
    process2 = Process(target=func2, args=(5, 20, 0.5), daemon=True)
    process1.start()
    process2.start()

    print("END")
```

Чтобы явно указать, что главный процесс должен дождаться работы дочерних процессов, нужно вызвать
метод `join` для каждого процесса.

```python
from multiprocessing import Process
import os
from time import sleep


def func(start, end, timeout):
    while start < end:
        print(f"Process {os.getpid()}: {start}")
        start += 1
        sleep(timeout)


if __name__ == "__main__":
    process1 = Process(target=func1, args=(3, 10, 1), daemon=True)
    process2 = Process(target=func2, args=(5, 20, 0.5), daemon=True)
    process1.start()
    process2.start()

    for index in range(5):
        print(f"Process {os.getpid()}: {index}")
        sleep(0.5)

    process1.join()
    process2.join()

    print("END")
```

Рассмотрим создание собственного класса процесса:

```python
from multiprocessing import Process
import os
from time import sleep


class MyProcess(Process):
    def __init__(self, begin, end, timeout):
        super().__init__(self)
        self.begin = begin
        self.end = end
        self.timeout = timeout

    def run(self):
        while self.begin < self.end:
            print(f"Process {os.getpid()}: {self.begin}")
            self.begin += 1
            sleep(self.timeout)


if __name__ == "__main__":
    process1 = MyProcess(begin=3, end=10, timeout=1)
    process2 = MyProcess(begin=5, end=20, timeout=0.5)

    process1.start()
    process2.start()

    for i in range(5):
        print("MAIN THREAD")
        sleep(0.5)

    process1.join()
    process2.join()

    print("END")
```

В процессах также можно использовать замки. Пример:

```python
from multiprocessing import Lock, Process
import os
from time import sleep


class MyProcess(Process):
    def __init__(self, begin, end, timeout, lock):
        super().__init__(self)
        self.begin = begin
        self.end = end
        self.timeout = timeout
        self.lock = lock

    def run(self):
        while self.begin < self.end:
            with self.lock:
                print(f"Process {os.getpid()}: {self.begin}")
                self.begin += 1
            sleep(self.timeout)


if __name__ == "__main__":
    lock = Lock()
    process1 = MyProcess(begin=3, end=10, timeout=1, lock=lock)
    process2 = MyProcess(begin=5, end=20, timeout=0.5, lock=lock)

    process1.start()
    process2.start()

    for i in range(5):
        print("MAIN THREAD")
        sleep(0.5)

    process1.join()
    process2.join()

    print("END")
```

## 5. Асинхронное программирование

Асинхронное программирование на Python становится все более популярным. Для этих целей существует
множество различных библиотек. Самая популярная из них – `asyncio`, которая является стандартной
библиотекой в Python с версии 3.4.

В каждой программе строки кода выполняются поочередно. Например, если у вас есть строка кода,
которая запрашивает что-либо с сервера, то это означает, что ваша программа не делает ничего во
время ожидания ответа. В некоторых случаях это допустимо, но во многих — нет. Одним из решений этой
проблемы являются потоки (threads).

Потоки дают возможность вашей программе выполнять ряд задач одновременно. Конечно, у потоков есть
ряд недостатков. Многопоточные программы являются более сложными и, как правило, более подвержены
ошибкам. Они включают в себя такие проблемы: состояние гонки (race condition), взаимная (deadlock) и
активная (livelock) блокировка, исчерпание ресурсов (resource starvation).

Асинхронное программирование — это потоковая обработка программного обеспечения/пользовательского
пространства, где приложение, а не процессор, управляет потоками и переключением контекста. В
асинхронном программировании контекст переключается только в заданных точках переключения, а не с
периодичностью, определенной CPU.

Изучим методы асинхронного программирования на примере библиотеки `asyncio`. Функции, которые
запускаются в конкурентном режиме называются корутины. Для того чтобы их запустить, нужно создать
цикл, в котором они будут выполнятся и в котором будет происходить переключение контекста.

Корутинами в Python-е представляются генераторы с операторами `yield from`, обёрнутые в декоратор
`asyncio.coroutine`.

```python
import asyncio


@asyncio.coroutine
def func(name, start, end, timeout):
    while start < end:
        print(f"Coroutine {name}: {start}")
        start += 1
        yield from asyncio.sleep(timeout)


loop = asyncio.get_event_loop()
futures = asyncio.gather(
    func("1", 3, 10, 1),
    func("2", 5, 20, 0.5),
)
print("START")
loop.run_until_complete(futures)
print("END")
```

С версии Python 3.5 вызовы `yield from` и декоратор `asyncio.coroutine` были заменены на директивы
`async/await`.

```python
import asyncio


async def func(name, start, end, timeout):
    while start < end:
        print(f"Coroutine {name}: {start}")
        start += 1
        await asyncio.sleep(timeout)


loop = asyncio.get_event_loop()
futures = asyncio.gather(
    func("1", 3, 10, 1),
    func("2", 5, 20, 0.5),
)
print("START")
loop.run_until_complete(futures)
print("END")
```

В корутине обязательно должен хоть раз вызываться метод `await`, иначе переключение контекста из
этой корутины не произойдёт никогда.

## 6. Домашнее задание

Обязательно:

* №3449 (<https://informatics.msk.ru/mod/statements/view3.php?id=3290&chapterid=3449>)
* №3457 (<https://informatics.msk.ru/mod/statements/view3.php?id=3309&chapterid=3457>)
* №3504 (<https://informatics.msk.ru/mod/statements/view3.php?id=3380&chapterid=3504>)
* №3506 (<https://informatics.msk.ru/mod/statements/view3.php?id=3380&chapterid=3506>)
* №3737 (<https://informatics.msk.ru/mod/statements/view3.php?id=3863&chapterid=3737>)
* №3738 (<https://informatics.msk.ru/mod/statements/view3.php?id=3863&chapterid=3738>)
